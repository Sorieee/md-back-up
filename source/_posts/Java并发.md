# 并发级别

​	根据控制并发的策略，我们可以把并发的级别分为阻塞、无饥饿、无障碍、无锁、无等待几种。

* 阻塞
* 无饥饿
  * 对于非公平锁来说，系统允许高优先级的线程插队。这样有可能导致低优先级线程产生饥饿。但如果锁是公平的，按照先来后到的规则，那么饥饿就不会产生，不管新来的线程优先级多高，要想获得资源，就必须乖乖排队，这样所有的线程都有机会执行。
* 无障碍（Obstruction-Free）
  * 无障碍是一种最弱的非阻塞调度。两个线程如果无障碍地执行，那么不会因为临界区的问题导致一方被挂起。换言之，大家都可以大摇大摆地进入临界区了。那么大家一起修改共享数据，把数据改坏了怎么办呢？对于无障碍的线程来说，一旦检测到这种情况，它就会立即对自己所做的修改进行回滚，确保数据安全。但如果没有数据竞争发生，那么线程就可以顺利完成自己的工作，走出临界区。
  * 如果说阻塞的控制方式是悲观策略，也就是说，系统认为两个线程之间很有可能发生不幸的冲突，因此以保护共享数据为第一优先级，相对来说，非阻塞的调度就是一种乐观的策略。它认为多个线程之间很有可能不会发生冲突，或者说这种概率不大。因此大家都应该无障碍地执行，但是一旦检测到冲突，就应该进行回滚。
* 无锁（Lock-Free）
  * 无锁的并行都是无障碍的。在无锁的情况下，所有的线程都能尝试对临界区进行访问，但不同的是，无锁的并发保证必然有一个线程能够在有限步内完成操作离开临界区。
  * 在无锁的调用中，一个典型的特点是可能会包含一个无穷循环。在这个循环中，线程会不断尝试修改共享变量。如果没有冲突，修改成功，那么程序退出，否则继续尝试修改。但无论如何，无锁的并行总能保证有一个线程是可以胜出的，不至于全军覆没。至于临界区中竞争失败的线程，它们必须不断重试，直到自己获胜。如果运气很不好，总是尝试不成功，则会出现类似饥饿的现象，线程会停止。
* 无等待（Wait-Free）
  * 无锁只要求有一个线程可以在有限步内完成操作，而无等待则在无锁的基础上更进一步扩展。它要求所有的线程都必须在有限步内完成，这样就不会引起饥饿问题。如果限制这个步骤的上限，还可以进一步分解为有界无等待和线程数无关的无等待等几种，它们之间的区别只是对循环次数的限制不同。
  * 一种典型的无等待结构就是RCU（Read Copy Update）。它的基本思想是，对数据的读可以不加控制。因此，所有的读线程都是无等待的，它们既不会被锁定等待也不会引起任何冲突。但在写数据的时候，先取得原始数据的副本，接着只修改副本数据（这就是为什么读可以不加控制），修改完成后，在合适的时机回写数据。

# Amdahl定律

阿姆达尔

​	加速比 = 优化前系统耗时 / 优化后系统耗时

​	所谓加速比就是优化前的耗时与优化后耗时的比值。加速比越高，表明优化效果越明显。图1.8显示了Amdahl公式的推导过程，其中n表示处理器个数，T表示时间，T1表示优化前耗时（也就是只有1个处理器时的耗时），Tn表示使用n个处理器优化后的耗时。F是程序中只能串行执行的比例。

![](https://pic.imgdb.cn/item/610aab135132923bf8cdfc4a.jpg)

# Gustafson定律

[ˈgʌstəfsən]

![](https://pic.imgdb.cn/item/610aab9c5132923bf8d07df8.jpg)

# JMM

* 原子性（Atomicity）
  * 原子性是指一个操作是不可中断的。
* 可见性（Visibility）
  * 可见性是指当一个线程修改了某一个共享变量的值时，其他线程是否能够立即知道这个修改。
* 有序性（Ordering）

# 线程&进程

* 进程（Process）是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。
* 线程就是轻量级进程，是程序执行的最小单位。使用多线程而不是用多进程去进行并发程序的设计，是因为线程间的切换和调度的成本远远小于进程。

**线程生命周期**

![](https://pic.imgdb.cn/item/610b5d955132923bf87f8a16.jpg)

## 线程启动

```java
	@Test
    public void newTread() {
        Thread thread = new Thread() {
            @Override
            public void run() {
                System.out.println("111");
            }
        };
        thread.start();
    }
```

## 终止线程

* 线程Thread提供了一个stop()方法。如果你使用stop()方法，就可以立即将一个线程终止，非常方便。但如果你使用Eclipse之类的IDE写代码，就会发现stop()方法是一个被标注为废弃的方法。也就是说，在将来，JDK可能就会移除该方法。
  * 为什么stop()方法被废弃而不推荐使用呢？原因是stop()方法过于暴力，强行把执行到一半的线程终止，可能会引起一些数据不一致的问题。
  * Thread.stop()方法在结束线程时，会直接终止线程，并立即释放这个线程所持有的锁，而这些锁恰恰是用来维持对象一致性的。如果此时，写线程写入数据正写到一半，并强行终止，那么对象就会被写坏，同时，由于锁已经被释放，另外一个等待该锁的读线程就顺理成章地读到了这个不一致的对象，悲剧也就此发生。整个过程如图2.4所示。

![](https://pic.imgdb.cn/item/610b60c45132923bf888ac00.jpg)



​	如果需要停止一个线程，那么应该怎么做呢？其实方法很简单，只需要由我们自行决定线程何时退出就可以了。仍然用本例说明，只需要将ChangeObjectThread线程增加一个stopMe()方法即可。

![](https://pic.imgdb.cn/item/610b611d5132923bf88979bf.jpg)

## 线程中断

* stop()方法停止线程的坏处，并且使用了一套自有的机制完善线程退出的功能。在JDK中是否有提供更强大的支持呢？答案是肯定的，那就是线程中断。

![](https://pic.imgdb.cn/item/610b614e5132923bf889ebbb.jpg)

​	Thread.interrupt()方法是一个实例方法。它通知目标线程中断，也就是设置中断标志位。中断标志位表示当前线程已经被中断了。Thread.isInterrupted()方法也是实例方法，它判断当前线程是否被中断（通过检查中断标志位）。最后的静态方法Thread.interrupted()也可用来判断当前线程的中断状态，但同时会清除当前线程的中断标志位状态。

​	下面这段代码对t1线程进行了中断，那么中断后t1会停止执行吗？

![](https://pic.imgdb.cn/item/610b624c5132923bf88c3caa.jpg)

​	在这里，虽然对t1进行了中断，但是在t1中并没有中断处理的逻辑，因此，即使t1线程被置为中断状态，这个中断也不会发生任何作用。

​	如果希望t1在中断后退出，就必须为它增加相应的中断处理代码：

![](https://pic.imgdb.cn/item/610b625f5132923bf88c703d.jpg)

​	Thread.sleep()方法会让当前线程休眠若干时间，它会抛出一个InterruptedException中断异常。InterruptedException不是运行时异常，也就是说程序必须捕获并且处理它，当线程在sleep()休眠时，如果被中断，这个异常就会产生。

![](https://pic.imgdb.cn/item/610b628e5132923bf88cf125.jpg)

​	注意上面代码中第10～15行，如果线程在第11行代码处被中断，则程序会抛出异常，并进入第13行代码处理。在catch子句部分，由于已经捕获了中断，我们可以立即退出线程。但在这里，我们并没有这么做，因为也许在这段代码中，我们还必须进行后续的处理来保证数据的一致性和完整性，因此，执行了Thread.interrupt()方法再次中断自己，置上中断标记位。只有这么做，在第6行代码的中断检查中，才能发现当前线程已经被中断了。

​	注意：Thread.sleep()方法由于中断而抛出异常，此时，它会清除中断标记，如果不加处理，那么在下一次循环开始时，就无法捕获这个中断，故在异常处理中，再次设置中断标记位。

## 等待（wait）和通知（notify）

* 等待wait()
* 通知notify()



​	当在一个对象实例上调用wait()方法后，当前线程就会在这个对象上等待。这是什么意思呢？比如，在线程A中，调用了obj.wait()方法，那么线程A就会停止继续执行，转为等待状态。等待到何时结束呢？线程A会一直等到其他线程调用了obj.notify()方法为止。这时，object对象俨然成了多个线程之间的有效通信手段。

​	如果一个线程调用了object.wait()方法，那么它就会进入object对象的等待队列。这个等待队列中，可能会有多个线程，因为系统运行多个线程同时等待某一个对象。当object.notify()方法被调用时，它就会从这个等待队列中随机选择一个线程，并将其唤醒。这里希望大家注意的是，这个选择是不公平的，并不是先等待的线程就会优先被选择，这个选择完全是随机的。

![](https://pic.imgdb.cn/item/610b79085132923bf8cdc35e.jpg)

​	除notify()方法外，Object对象还有一个类似的notifyAll()方法，它和notify()方法的功能基本一致，不同的是，它会唤醒在这个等待队列中所有等待的线程，而不是随机选择一个。

​	这里还需要强调一点，Object.wait()方法并不能随便调用。它必须包含在对应的synchronzied语句中，无论是wait()方法或者notify()方法都需要首先获得目标对象的一个监视器。图2.6显示了wait()方法和notify()方法的工作流程细节。其中T1和T2表示两个线程。T1在正确执行wait()方法前，必须获得object对象的监视器。而wait()方法在执行后，会释放这个监视器。这样做的目的是使其他等待在object对象上的线程不至于因为T1的休眠而全部无法正常执行。

​	线程T2在notify()方法调用前，也必须获得object对象的监视器。所幸，此时T1已经释放了这个监视器。因此，T2可以顺利获得object对象的监视器。接着，T2执行了notify()方法尝试唤醒一个等待线程，这里假设唤醒了T1。T1在被唤醒后，要做的第一件事并不是执行后续的代码，而是要尝试重新获得object对象的监视器，而这个监视器也正是T1在wait()方法执行前所持有的那个。如果暂时无法获得，则T1还必须等待这个监视器。当监视器顺利获得后，T1才可以在真正意义上继续执行。

![](https://pic.imgdb.cn/item/610b798d5132923bf8cf9823.jpg)

​	注意：Object.wait()方法和Thread.sleep()方法都可以让线程等待若干时间。除wait()方法可以被唤醒外，另外一个主要区别就是wait()方法会释放目标对象的锁，而Thread.sleep()方法不会释放任何资源。

## 挂起（suspend）和继续执行（resume）线程

​	不推荐使用suspend()方法去挂起线程是因为suspend()方法在导致线程暂停的同时，并不会释放任何锁资源。此时，其他任何线程想要访问被它占用的锁时，都会被牵连，导致无法正常继续运行（如图2.7所示）。直到对应的线程上进行了resume()方法操作，被挂起的线程才能继续，从而其他所有阻塞在相关锁上的线程也可以继续执行。但是，如果resume()方法操作意外地在suspend()方法前就执行了，那么被挂起的线程可能很难有机会被继续执行。并且，更严重的是：它所占用的锁不会被释放，因此可能会导致整个系统工作不正常。而且，对于被挂起的线程，从它的线程状态上看，居然还是Runnable，这也会严重影响我们对系统当前状态的判断。

![](https://pic.imgdb.cn/item/610bad095132923bf852e232.jpg)

​	如果需要一个比较可靠的suspend()方法，那么应该怎么办呢？回想一下上一节中提到的wait()方法和notify()方法，这也不是一件难事。下面的代码就给出了一个利用wait()方法和notify()方法，在应用层面实现suspend()方法和resume()方法功能的例子。

![](https://pic.imgdb.cn/item/610bad3b5132923bf85331ee.jpg)

![](https://pic.imgdb.cn/item/610bad495132923bf85348ae.jpg)

### 等待线程结束（join）和谦让（yield）

![](https://pic.imgdb.cn/item/610bb0075132923bf857d85e.jpg)

​	第一个join()方法表示无限等待，它会一直阻塞当前线程，直到目标线程执行完毕。第二个方法给出了一个最大等待时间，如果超过给定时间目标线程还在执行，当前线程也会因为“等不及了”，而继续往下执行。

​	join()方法的本质是让调用线程wait()方法在当前线程对象实例上。下面是JDK中join()方法实现的核心代码片段：

![](https://pic.imgdb.cn/item/610bb03d5132923bf8583ce8.jpg)

​	这是一个静态方法，一旦执行，它会使当前线程让出CPU。但要注意，让出CPU并不表示当前线程不执行了。当前线程在让出CPU后，还会进行CPU资源的争夺，但是是否能够再次被分配到就不一定了。因此，对Thread.yield()方法的调用就好像是在说：“我已经完成了一些最重要的工作了，我可以休息一下了，可以给其他线程一些工作机会啦！”

​	如果你觉得一个线程不那么重要，或者优先级非常低，而且又害怕它会占用太多的CPU资源，那么可以在适当的时候调用Thread.yield()方法，给予其他重要线程更多的工作机会。

# volatile与Java内存模型（JMM）

![](https://pic.imgdb.cn/item/610bb1025132923bf8595288.jpg)

​	在虚拟机的Client模式下，由于JIT并没有做足够的优化，在主线程修改ready变量的状态后，ReaderThread可以发现这个改动，并退出程序。但是在Server模式下，由于系统优化的结果，ReaderThread线程无法“看到”主线程中的修改，导致ReaderThread永远无法退出（因为代码第7行判断永远不会成立），这显然不是我们想看到的结果。这个问题就是一个典型的可见性问题。

​	和原子性问题一样，我们只要简单地使用关键字volatile来声明ready变量，告诉Java虚拟机，这个变量可能会在不同的线程中修改。这样，就可以顺利解决这个问题了。

# 分门别类的管理：线程组

​	在一个系统中，如果线程数量很多，而且功能分配比较明确，就可以将相同功能的线程放置在同一个线程组里。

​	线程组的使用非常简单，如下：

![](https://pic.imgdb.cn/item/610bb1905132923bf85a2497.jpg)

​	此外，对于编码习惯，我还想再多说几句。强烈建议大家在创建线程和线程组的时候，给它们取一个好听的名字。对于计算机来说，也许名字并不重要，但是在系统出现问题时，你很有可能会导出系统内所有线程，你拿到的如果是一连串的Thread-0、Thread-1、Thread-2，我想你一定会头疼。而你看到的如果是类似HttpHandler、FTPService这样的名字，则会心情倍爽。

# 驻守后台：守护线程（Daemon）

​	守护线程是一种特殊的线程，就和它的名字一样，它是系统的守护者，在后台默默地完成一些系统性的服务，比如垃圾回收线程、JIT线程就可以理解为守护线程。与之相对应的是用户线程，用户线程可以认为是系统的工作线程，它会完成这个程序应该要完成的业务操作。如果用户线程全部结束，则意味着这个程序实际上无事可做了。守护线程要守护的对象已经不存在了，那么整个应用程序就应该结束。因此，当一个Java应用内只有守护线程时，Java虚拟机就会自然退出。

```java
t.setDaemon(true);
```

​	设置守护线程必须在线程start()之前设置，否则你会得到一个类似以下的异常，告诉你守护线程设置失败。

# 先做重要的事：线程优先级

​	在Java中，使用1到10表示线程优先级。一般可以使用内置的三个静态标量表示：

![](https://pic.imgdb.cn/item/610bb2a45132923bf85bb0b6.jpg)

# 线程安全的概念与关键字synchronized

​	关键字synchronized的作用是实现线程间的同步。它的工作是对同步的代码加锁，使得每一次，只能有一个线程进入同步块，从而保证线程间的安全性。

​	关键字synchronized可以有多种用法，这里做一个简单的整理。

* 指定加锁对象：对给定对象加锁，进入同步代码前要获得给定对象的锁。
* 直接作用于实例方法：相当于对当前实例加锁，进入同步代码前要获得当前实例的锁。
* 直接作用于静态方法：相当于对当前类加锁，进入同步代码前要获得当前类的锁。

# 程序中的幽灵：隐蔽的错误

* 无提示错误案例
  * 溢出
* 并发下的ArrayList
  * 程序正常结束，ArrayList的最终大小确实200万。这说明即使并行程序有问题，也未必会每次都表现出来。
  * 程序抛出异常。这是因为ArrayList在扩容过程中，内部一致性被破坏，但由于没有锁的保护，另外一个线程访问到了不一致的内部状态，导致出现越界问题。
  * 出现了一个非常隐蔽的错误，大小并非200w。
* 并发下诡异的HashMap



**错误加锁**

![](https://pic.imgdb.cn/item/610bd9e35132923bf8901000.jpg)

​	要解释这个问题，得从Integer说起。在Java中，Integer属于不变对象，即对象一旦被创建，就不可能被修改。也就是说，如果你有一个Integer对象代表1，那么它就永远表示1，你不可能修改Integer对象的值，使它为2。那如果你需要2怎么办呢？也很简单，新建一个Integer对象，并让它表示2即可。

![](https://pic.imgdb.cn/item/610bdad15132923bf890fc73.jpg)

# ReentrantLock

![](https://pic.imgdb.cn/item/610bdb015132923bf8912880.jpg)

​	重入锁还提供了一些高级功能。

**1.中断响应**

​	对于关键字synchronized来说，如果一个线程在等待锁，那么结果只有两种情况，要么它获得这把锁继续执行，要么它就保持等待。而使用重入锁，则提供另外一种可能，那就是线程可以被中断。也就是在等待锁的过程中，程序可以根据需要取消对锁的请求。有些时候，这么做是非常有必要的。比如，你和朋友约好一起去打球，如果你等了半个小时朋友还没有到，你突然接到一个电话，说由于突发情况，朋友不能如约前来了，那么你一定扫兴地打道回府了。中断正是提供了一套类似的机制。如果一个线程正在等待锁，那么它依然可以收到一个通知，被告知无须等待，可以停止工作了。这种情况对于处理死锁是有一定帮助的。

![](https://pic.imgdb.cn/item/610bdc135132923bf8922164.jpg)

![](https://pic.imgdb.cn/item/610bdc205132923bf8922dd3.jpg)

**2.锁申请等待限时**

​	除了等待外部通知之外，要避免死锁还有另外一种方法，那就是限时等待。依然以约朋友打球为例，如果朋友迟迟不来，又无法联系到他，那么在等待1到2个小时后，我想大部分人都会扫兴离去。对线程来说也是这样。通常，我们无法判断为什么一个线程迟迟拿不到锁。也许是因为死锁了，也许是因为产生了饥饿。如果给定一个等待时间，让线程自动放弃，那么对系统来说是有意义的。我们可以使用tryLock()方法进行一次限时的等待。

​	tryLock()方法接收两个参数，一个表示等待时长，另外一个表示计时单位。这里的单位设置为秒，时长为5，表示线程在这个锁请求中最多等待5秒。如果超过5秒还没有得到锁，就会返回false。如果成功获得锁，则返回true。

​	ReentrantLock.tryLock()方法也可以不带参数直接运行。在这种情况下，当前线程会尝试获得锁，如果锁并未被其他线程占用，则申请锁会成功，并立即返回true。如果锁被其他线程占用，则当前线程不会进行等待，而是立即返回false。这种模式不会引起线程等待，因此也不会产生死锁。

**3.公平锁**

​	![](https://pic.imgdb.cn/item/610be0a65132923bf896e6d4.jpg)

​	当参数fair为true时，表示锁是公平的。公平锁看起来很优美，但是要实现公平锁必然要求系统维护一个有序队列，因此公平锁的实现成本比较高，性能却非常低下，因此，在默认情况下，锁是非公平的。如果没有特别的需求，则不需要使用公平锁。公平锁和非公平锁在线程调度表现上也是非常不一样的。

就重入锁的实现来看，它主要集中在Java层面。在重入锁的实现中，主要包含三个要素。

​	第一，原子状态。原子状态使用CAS操作（在第4章进行详细讨论）来存储当前锁的状态，判断锁是否已经被别的线程持有了。

​	第二，等待队列。所有没有请求到锁的线程，会进入等待队列进行等待。待有线程释放锁后，系统就能从等待队列中唤醒一个线程，继续工作。

​	第三，阻塞原语park()和unpark()，用来挂起和恢复线程。没有得到锁的线程将会被挂起。有关park()和unpark()的详细介绍，可以参考第3.1.7节线程阻塞工具类：LockSupport。

# 重入锁的好搭档：Condition

​	如果大家理解了Object.wait()方法和Object.notify()方法，就能很容易地理解Condition对象了。它与wait()方法和notify()方法的作用是大致相同的。但是wait()方法和notify()方法是与synchronized关键字合作使用的，而Condition是与重入锁相关联的。通过lock接口（重入锁就实现了这一接口）的ConditionnewCondition()方法可以生成一个与当前重入锁绑定的Condition实例。利用Condition对象，我们就可以让线程在合适的时间等待，或者在某一个特定的时刻得到通知，继续执行。

* await()方法会使当前线程等待，同时释放当前锁，当其他线程中使用signal()方法或者signalAll()方法时，线程会重新获得锁并继续执行。或者当线程被中断时，也能跳出等待。这和Object.wait()方法相似。
* awaitUninterruptibly()方法与await()方法基本相同，但是它并不会在等待过程中响应中断。
* singal()方法用于唤醒一个在等待中的线程，singalAll()方法会唤醒所有在等待中的线程。这和Obejct.notify()方法很类似。

![](https://pic.imgdb.cn/item/610be56c5132923bf89bbc8b.jpg)



# 信号量（Semaphore）

![](https://pic.imgdb.cn/item/610be68b5132923bf89cf778.jpg)

## ReadWriteLock读写锁

​	ReadWriteLock是JDK 5中提供的读写分离锁。读写分离锁可以有效地帮助减少锁竞争，提升系统性能。用锁分离的机制来提升性能非常容易理解，比如线程A1、A2、A3进行写操作，B1、B2、B3进行读操作，如果使用重入锁或者内部锁，从理论上说所有读之间、读与写之间、写和写之间都是串行操作。

![](https://pic.imgdb.cn/item/610be7bf5132923bf89e4b97.jpg)

# 倒计数器：CountDownLatch

​	CountDownLatch的构造函数接收一个整数作为参数，即当前这个计数器的计数个数。

```java
public CountDownLatch(int count);
c.countDown();

c.await(); //等待
```

主线程在CountDownLatch上等待，当所有检查任务全部完成后，主线程方能继续执行。

# 循环栅栏：CyclicBarrier

​	CyclicBarrier比CountDownLatch略微强大一些，它可以接收一个参数作为barrierAction。所谓barrierAction就是当计数器一次计数完成后，系统会执行的动作。如下构造函数，其中，parties表示计数总数，也就是参与的线程总数。

​	CyclicBarrier.await()方法可能会抛出两个异常。一个是InterruptedException，也就是在等待过程中，线程被中断，应该说这是一个非常通用的异常。大部分迫使线程等待的方法都可能会抛出这个异常，使得线程在等待时依然可以响应外部紧急事件。另外一个异常则是CyclicBarrier特有的BrokenBarrierException。一旦遇到这个异常，则表示当前的CyclicBarrier已经破损了，可能系统已经没有办法等待所有线程到齐了。如果继续等待，可能就是徒劳无功的，因此，还是“打道回府”吧！

![](https://pic.imgdb.cn/item/610beac65132923bf8a1ad7a.jpg)

# 线程阻塞工具类：LockSupport

​	LockSupport是一个非常方便实用的线程阻塞工具，它可以在线程内任意位置让线程阻塞。与Thread.suspend()方法相比，它弥补了由于resume()方法发生导致线程无法继续执行的情况。和Object.wait()方法相比，它不需要先获得某个对象的锁，也不会抛出InterruptedException异常。

​	LockSupport的静态方法park()可以阻塞当前线程，类似的还有parkNanos()、parkUntil()等方法。它们实现了一个限时的等待。

​	LockSupport的静态方法park()可以阻塞当前线程，类似的还有parkNanos()、parkUntil()等方法。它们实现了一个限时的等待。

​	LockSupport类使用类似信号量的机制。它为每一个线程准备了一个许可，如果许可可用，那么park()方法会立即返回，并且消费这个许可（也就是将许可变为不可用），如果许可不可用，就会阻塞，而unpark()方法则使得一个许可变为可用（但是和信号量不同的是，许可不能累加，你不可能拥有超过一个许可，它永远只有一个）。

​	这个特点使得：即使unpark()方法操作发生在park()方法之前，它也可以使下一次的park()方法操作立即返回。这也就是上述代码可顺利结束的主要原因。

​	同时，处于park()方法挂起状态的线程不会像suspend()方法那样还给出一个令人费解的Runnable状态。它会非常明确地给出一个WAITING状态，甚至还会标注是park()方法引起的。

​	除了有定时阻塞的功能，LockSupport.park()方法还能支持中断影响。但是和其他接收中断的函数很不一样，LockSupport.park()方法不会抛出InterruptedException异常。它只会默默返回，但是我们可以从Thread.interrupted()等方法中获得中断标记。

![](https://pic.imgdb.cn/item/610bee105132923bf8a56237.jpg)

# Guava和RateLimiter限流

更为一般化的限流算法有两种：漏桶算法和令牌桶算法。

​	漏桶算法的基本思想是：利用一个缓存区，当有请求进入系统时，无论请求的速率如何，都先在缓存区内保存，然后以固定的流速流出缓存区进行处理，如图3.4所示。

![](https://pic.imgdb.cn/item/610bf0d15132923bf8a8dd4b.jpg)

​	令牌桶算法是一种反向的漏桶算法。在令牌桶算法中，桶中存放的不再是请求，而是令牌。处理程序只有拿到令牌后，才能对请求进行处理。如果没有令牌，那么处理程序要么丢弃请求，要么等待可用的令牌。为了限制流速，该算法在每个单位时间产生一定量的令牌存入桶中。比如，要限定应用每秒只能处理1个请求，那么令牌桶就会每秒产生1个令牌。通常，桶的容量是有限的，比如，当令牌没有被消耗掉时，只能累计有限单位时间内的令牌数量，其基本原理如图3.5所示。

![](https://pic.imgdb.cn/item/610bf0e85132923bf8a8f924.jpg)

![](https://pic.imgdb.cn/item/610bf0fb5132923bf8a90ed9.jpg)

​	但在有些场景中，如果系统无法处理请求，为了保证服务质量，更倾向于直接丢弃过载请求，从而避免可能的崩溃，此时，则可以使用tryAcquire()方法，如下所示。

![](https://pic.imgdb.cn/item/610bf1965132923bf8a9f18b.jpg)

# 线程复用：线程池

* newFixedThreadPool()方法：该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理任务队列中的任务。
* newSingleThreadExecutor()方法：该方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。
* newCachedThreadPool()方法：该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。
* newSingleThreadScheduledExecutor()方法：该方法返回一个ScheduledExecutorService对象，线程池大小为1。ScheduledExecutorService接口在ExecutorService接口之上扩展了在给定时间执行某任务的功能，如在某个固定的延时之后执行，或者周期性执行某个任务。
* newScheduledThreadPool()方法：该方法也返回一个ScheduledExecutorService对象，但该线程池可以指定线程数量。

**2．计划任务**

​	另外一个值得注意的方法是newScheduledThreadPool()。它返回一个ScheduledExecutorService对象，可以根据时间需要对线程进行调度。它的一些主要方法如下：

![](https://pic.imgdb.cn/item/610bf2bf5132923bf8ab8db5.jpg)

​	作为说明，这里给出了三个方法。方法schedule()会在给定时间，对任务进行一次调度。方法scheduleAtFixedRate()和方法scheduleWithFixedDelay()会对任务进行周期性的调度，但是两者有一点小小的区别，如图3.8所示。

![](https://pic.imgdb.cn/item/610bf3d25132923bf8acf39e.jpg)

对于FixedRate方式来说，任务调度的频率是一定的。它是以上一个任务开始执行时间为起点，在之后的period时间调度下一次任务。而FixDelay方式则是在上一个任务结束后，再经过delay时间进行任务调度。

**刨根究底：核心线程池的内部实现**

![](https://pic.imgdb.cn/item/610bf42f5132923bf8ad64c0.jpg)	

函数的参数含义如下。

* corePoolSize：指定了线程池中的线程数量。
*  maximumPoolSize：指定了线程池中的最大线程数量。
* keepAliveTime：当线程池线程数量超过corePoolSize时，多余的空闲线程的存活时间，即超过corePoolSize的空闲线程，在多长时间内会被销毁。
*  unit：keepAliveTime的单位。
* workQueue：任务队列，被提交但尚未被执行的任务。
* threadFactory：线程工厂，用于创建线程，一般用默认的即可。
* handler：拒绝策略。当任务太多来不及处理时，如何拒绝任务。



​	参数workQueue指被提交但未执行的任务队列，它是一个BlockingQueue接口的对象，仅用于存放Runnable对象。根据队列功能分类，在ThreadPoolExecutor类的构造函数中可使用以下几种BlockingQueue接口。

* 直接提交的队列：该功能由SynchronousQueue对象提供。SynchronousQueue是一个特殊的BlockingQueue。SynchronousQueue没有容量，每一个插入操作都要等待一个相应的删除操作，反之，每一个删除操作都要等待对应的插入操作。如果使用SynchronousQueue，则提交的任务不会被真实地保存，而总是将新任务提交给线程执行，如果没有空闲的进程，则尝试创建新的进程，如果进程数量已经达到最大值，则执行拒绝策略。因此，使用SynchronousQueue队列，通常要设置很大的maximumPoolSize值，否则很容易执行拒绝策略。
* 有界的任务队列：有界的任务队列可以使用ArrayBlockingQueue类实现。ArrayBlockingQueue类的构造函数必须带一个容量参数，表示该队列的最大容量：



​	当使用有界的任务队列时，若有新的任务需要执行，如果线程池的实际线程数小于corePoolSize，则会优先创建新的线程，若大于corePoolSize，则会将新任务加入等待队列。若等待队列已满，无法加入，则在总线程数不大于maximumPoolSize的前提下，创建新的进程执行任务。若大于maximumPoolSize，则执行拒绝策略。可见，有界队列仅当在任务队列装满时，才可能将线程数提升到corePoolSize以上，换言之，除非系统非常繁忙，否则要确保核心线程数维持在corePoolSize。

* 无界的任务队列：无界任务队列可以通过LinkedBlockingQueue类实现。与有界队列相比，除非系统资源耗尽，否则无界的任务队列不存在任务入队失败的情况。当有新的任务到来，系统的线程数小于corePoolSize时，线程池会生成新的线程执行任务，但当系统的线程数达到corePoolSize后，就不会继续增加了。若后续仍有新的任务加入，而又没有空闲的线程资源，则任务直接进入队列等待。若任务创建和处理的速度差异很大，无界队列会保持快速增长，直到耗尽系统内存。
* 优先任务队列：优先任务队列是带有执行优先级的队列。它通过PriorityBlockingQueue类实现，可以控制任务的执行先后顺序。它是一个特殊的无界队列。无论是有界队列ArrayBlockingQueue类，还是未指定大小的无界队列LinkedBlockingQueue类都是按照先进先出算法处理任务的。而PriorityBlockingQueue类则可以根据任务自身的优先级顺序先后执行，在确保系统性能的同时，也能有很好的质量保证（总是确保高优先级的任务先执行）。



​	注意：使用自定义线程池时，要根据应用的具体情况，选择合适的并发队列作为任务的缓冲。当线程资源紧张时，不同的并发队列对系统行为和性能的影响均不同。

## **超负载了怎么办：拒绝策略**

* AbortPolicy策略：该策略会直接抛出异常，阻止系统正常工作。
* CallerRunsPolicy策略：只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。
* DiscardOldestPolicy策略：该策略将丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。
* DiscardPolicy策略：该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，我觉得这可能是最好的一种方案了吧！



​	以上内置的策略均实现了RejectedExecutionHandler接口，若以上策略仍无法满足实际应用的需要，完全可以自己扩展RejectedExecutionHandler接口。RejectedExecutionHandler的定义如下：

![](https://pic.imgdb.cn/item/610bf7645132923bf8b16660.jpg)

## 自定义线程创建：ThreadFactory

![](https://pic.imgdb.cn/item/610bf7d25132923bf8b1e906.jpg)

## 我的应用我做主：扩展线程池

​	虽然JDK已经帮我们实现了这个稳定的高性能线程池，但如果我们需要对这个线程池做一些扩展，比如，监控每个任务执行的开始时间和结束时间，或者其他一些自定义的增强功能，这时候应该怎么办呢？

​	一个好消息是：ThreadPoolExecutor是一个可以扩展的线程池。它提供了beforeExecute()、afterExecute()和terminated()三个接口用来对线程池进行控制。

## 合理的选择：优化线程池线程数量

​	线程池的大小对系统的性能有一定的影响。过大或者过小的线程数量都无法发挥最优的系统性能，但是线程池大小的确定也不需要做得非常精确，因为只要避免极大和极小两种情况，线程池的大小对系统的性能并不会影响太大。一般来说，确定线程池的大小需要考虑CPU数量、内存大小等因素。在Java Concurrency inPractice一书中给出了估算线程池大小的公式：

​	Ncpu = CPU的数量

​	Ucpu =目标CPU的使用率，0≤Ucpu≤1

​	W/C = 等待时间与计算时间的比率

​	为保持处理器达到期望的使用率，最优的线程池的大小等于：在Java中，可以通过如下代码取得可用的CPU数量。

​	Nthreads = Ncpu×Ucpu×(1 + W/C)

## 堆栈去哪里了：在线程池中寻找堆栈

​	使用线程池虽然是件好事，但是还是得处处留意这些“坑”。线程池很有可能会“吃”掉程序抛出的异常，导致我们对程序的错误一无所知。

​	异常堆栈对于程序员的重要性就好像指南针对于航行在茫茫大海上的轮船。没有指南针，轮船只能更艰难地寻找方向，没有异常堆栈，排查问题时，也只能慢慢琢磨了。我的一个领导曾经说过：“最鄙视那些出错不打印异常堆栈的行为！”我相信，任何一个得益于异常堆栈而快速定位问题的程序员，一定都对这句话深有体会。这里我们将和大家讨论向线程池讨回异常堆栈的方法。

![](https://pic.imgdb.cn/item/610bf8835132923bf8b2b0a2.jpg)

​	注意了，我这里说的是部分。这是因为从这两个异常堆栈中我们只能知道异常是在哪里抛出的（这里是DivTask的第11行）。但是我们还希望得到另外一个更重要的信息，那就是这个任务到底是在哪里提交的？而任务的具体提交位置已经被线程池完全淹没了。顺着堆栈，我们最多只能找到线程池中的调度流程，而这对于我们几乎是没有价值的。

​	既然这样，我们只能自己动手，丰衣足食啦！为了今后少加几天班，非常有必要将堆栈的信息彻底挖出来！扩展我们的ThreadPoolExecutor线程池，让它在调度任务之前，先保存一下提交任务线程的堆栈信息：

![](https://pic.imgdb.cn/item/610bf8af5132923bf8b2e4f9.jpg)

## 分而治之：Fork/Join框架

​	也就是使用fork()方法后系统多了一个执行分支（线程），所以需要等待这个执行分支执行完毕，才有可能得到最终的结果，因此join()方法就表示等待。

​	在JDK中，给出了一个ForkJoinPool线程池，对于fork()方法并不急着开启线程，而是提交给ForkJoinPool线程池进行处理，以节省系统资源。使用Fork/Join框架进行数据处理时的总体结构如图3.11所示。

​	由于线程池的优化，提交的任务和线程数量并不是一对一的关系。在绝大多数情况下，一个物理线程实际上是需要处理多个逻辑任务的。因此，每个线程必然需要拥有一个任务队列。因此，在实际执行过程中，可能遇到这么一种情况：线程A已经把自己的任务都执行完了，而线程B还有一堆任务等着处理，此时，线程A就会“帮助”线程B，从线程B的任务队列中拿一个任务过来处理，尽可能地达到平衡。图3.12显示了这种互相帮助的精神。一个值得注意的地方是，当一个线程试图“帮助”其他线程时，总是从任务队列的底部开始获取数据，而线程试图执行自己的任务时，则是从相反的顶部开始获取数据。因此这种行为也十分有利于避免数据竞争。

![](https://pic.imgdb.cn/item/610bf9695132923bf8b3b65a.jpg)

![](https://pic.imgdb.cn/item/610bf9805132923bf8b3d100.jpg)

![](https://pic.imgdb.cn/item/610bf9c55132923bf8b42608.jpg)

![](https://pic.imgdb.cn/item/610bf9fe5132923bf8b46ac6.jpg)

![](https://pic.imgdb.cn/item/610bfa145132923bf8b484f6.jpg)

​	在使用Fork/Join框架时需要注意：如果任务的划分层次很多，一直得不到返回，那么可能出现两种情况。第一，系统内的线程数量越积越多，导致性能严重下降。第二，函数的调用层次变多，最终导致栈溢出。不同版本的JDK内部实现机制可能有差异，从而导致其表现不同。

​	此外，ForkJoin线程池使用一个无锁的栈来管理空闲线程。如果一个工作线程暂时取不到可用的任务，则可能会被挂起，挂起的线程将会被压入由线程池维护的栈中。待将来有任务可用时，再从栈中唤醒这些线程。

## Guava中对线程池的扩展

**1.特殊的DirectExecutor线程池**

​	在MoreExecutors中，提供了一个简单但是非常重要的线程池实现，即DirectExecutor线程池。DirectExecutor线程池很简单，它并没有真的创建或者使用额外线程，它总是将任务在当前线程中直接执行。读者也许会觉得很奇怪，为什么需要这么一个线程池呢？这是软件设计上的需要。

​	从软件设计的角度上说，抽象是软件设计的根本和精髓。将不同业务的共同属性提取并抽象成模型非常有利于对不同业务的统一处理。我们总是希望并且倾向于使用通用的代码来处理不同的场景，因此，这就需要对不同场景进行统一的抽象和建模。

​	对于线程池来说，其技术目的是为了复用线程以提高运行效率，但其业务需求却是去异步执行一段业务指令。但是有时候，异步并不是必要的。因此，当我们剥去线程池的技术细节，仅关注其使用场景时便不难发现，任何一个可以运行Runnable实例的模块都可以被视为线程池，即便它没有真正创建线程。这样就可以将异步执行和同步执行进行统一，使用统一的编码风格来处理同步和异步调用，进而简化设计。

**2.Daemon线程池**

​	此外，在MoreExecutors中，还提供了将普通线程池转为Daemon线程池的方法。在很多场合，我们并不希望后台线程池阻止程序的退出，当系统执行完成后，即便有线程池存在，依然希望进程结束执行。此时，就可以使用MoreExecutors.getExitingExecutorService()方法。

**3.对Future模式的扩展**

​	在MoreExecutors中还提供了对Future模式的扩展，这部分内容将在第5.5节Future模式中介绍。

