# 1. 综述

## 1.1 业务发展离不开微服务治理保驾护航

### 业务快速发展期

**1.开发测试提效**

a.【开发环境隔离】传统的多套开发环境，需要使⽤多套的物理环境，才能实现多套环境各⾃独⽴互不⼲扰，但是多套物理环境的隔离的机器成本是很⾼的，基本上不⼤能接受。但通过全链路灰度这种逻辑隔离的⽅式实现开发环境隔离，可以在不增加成本的情况下增加多套开发测试环境，助你实现敏捷开发。

b.【⾃动化回归测试】⾃动化回归测试功能，可以将多个测试⽤例串联成测试⽤例集，将上⼀条测试的返回值作为下⼀跳测试⼊参，串联成具体的业务场景并沉淀到⾃动化回归测试中，在每⼀次的发版之前都跑⼀次⾃动化回归来验证功能的正确性，这样就可以⼤⼤节省测试的⼈⼒成本。更进⼀步，还可以通过流量录制回放功能，将线上的真实流量录制下来，并沉淀成⾃动化回归⽤例集，在测试环境进⾏流量回放，更进⼀步地提升测试case 的覆盖率。

c.【服务契约】功能越来越多，迭代越来越快，API 越来越复杂，团队之间沟通的效率越来越低，API ⽂档严重过期。如果能⾃动⽣成服务契约，可以有效地避免⽂档腐化造成的开发效率低下的问题。

**2.安全发布**

a.【⽆损下线】⽆损下线问题的根本原因是开源的微服务体系没有确保应⽤提供者节点在停⽌服务前确保已经通知到所有消费者不再调⽤⾃⼰，也⽆法确保在处理完所有请求之后再停⽌应⽤。所以新发版的应⽤，即使业务代码没有任何问题，也可能在发布过程影响⽤户的体验。

b.【⽆损上线】⽆损上线问题出现的原因是因为在某些场景下服务提供者，需要经过⼀段时间才能正常地接收⼤流量的请求并成功返回。同时在K8s 场景下，还需要和K8s 中的readiness 、滚动发布等⽣命周期紧密结合，才能确保应⽤发布过程中能不出现业务报错。

c.【全链路灰度】新功能上线之后，可以通过灰度规则控制哪些⽤户可以使⽤。这样可以先选择让内部⽤户使⽤，测试新功能的正确性。当内部⽤户验证通过后，再渐渐地扩⼤灰度范围，确保每个功能都经过充分验证后再全量开放给客户，屏蔽掉发布新功能的⻛险。⽽且当出现问题时，可以通过修改灰度规则来实现快速回滚，做到新版本发版时⼏乎⽆⻛险。

**3.屏蔽偶发异常导致的⻛险**

a.【离群实例摘除】对于这些偶发的异常问题，离群摘除功能可以智能判断应⽤中的服务提供者某个出现了问题，智能地在⼀段时间内屏蔽掉这个服务提供者，保证业务的正常，等这个服务提供者恢复过来之后再进⾏调⽤。可以在应⽤节点出现偶发异常时，智能屏蔽掉此节点，以免影响业务，等此节点恢复后再继续提供服务，从⽽屏蔽偶发异常导致的⻛险。

​	据统计数据显示，有将近90%的线上故障是由于发版过程中出现的，剩下的10% 左右的线上问题，可能是由于⼀些偶然的原因导致的。⽐如偶然的⽹络故障、机器I/O 出现问题、或者是某台机器负载过⾼等。在解决了发布时候的稳定性问题和偶发异常导致的⻛险后，基本能够确保线上业务不会出现灾难性的问题。

### 业务成熟期

​	低成本创新：虽然发展不像原来那么迅速，但是业务创新探索的诉求仍旧存在，由于业务规模的扩⼤，创新的成本也在增加。这个时候不仅是需要快速开发迭代，更⼤的需求是⽤尽可能⼩的成本进⾏创新探索测试，有时候还需要使⽤上AB 测试的⼿段进⾏实验⽐较。

​	容灾多活：由于业务规模已经很⼤了，治理中的稳定性的诉求更加强烈，⽽且随着业务范围的扩⼤，应⽤也开始在多个地域、多个云产品中进⾏部署。同城容灾、异地多活这类需求也开始出现。

​	问题定位：出现任何问题都必须彻查。虽然出现问题时，业务恢复仍旧排查第⼀位，但是业务恢复之后的问题根因定位也是不能少的，因为如果不彻查，难免后续出现同样的问题。

​	⻛险预案：紧急预案、⻛险预防也变得⾮常重要，需要提前做好业务的保护和降级的埋点演练，在遇到绝⼤多数可预⻅问题可以紧急修复，出现不可控问题时，可以通过预案⼿段执⾏预案，确保整体业务的可控性。

## 1.2 微服务治理在云原⽣场景下的挑战

​	我们分析了阿⾥云典型客户的实践经历，业务上云通常划分为4 个阶段：云上部署、云原⽣部署、微服务化、服务治理。

![](https://pic.imgdb.cn/item/62a601de09475431299b9c82.jpg)

#### 云上部署

​	这⼀阶段我们解决的问题，如何把传统业务，原来是跑在⾃建IDC 机房的业务，能够原封不动的迁移到云上。通常云⼚商提供了丰富的计算，存储，⽹络等资源可供选择，以虚拟化技术，神⻰裸⾦属服务为代表的硬件可以满⾜企业客户上云搬迁的丰富需求，这⼀阶段关注的焦点是资源，对于业务并⽆任何的改造，只需要从本地原样搬迁到云上即可。

#### 云原⽣部署

​	云原⽣是释放云计算价值的最短路径，以容器技术为代表，云原⽣提供了强⼤的调度，弹性等能⼒，极⼤的降低了上云的成本。这⼀阶段我们关注的⽬标主要是业务进⾏云原⽣化改造，随着Kubernetes 作为容器编排市场的事实标准，我们需要把业务从原来的的虚拟机部署⽅式改造成容器化⽅式，部署并运⾏在K8s 之上，最⼤限度享受到云原⽣带来的技术红利。这⼀阶段核⼼关注⽬标以容器为核⼼。

#### 微服务化

​	当我们的业务规模逐步扩⼤，传统单体应⽤很难进⼀步⽀撑业务的发展，业务的迭代速度已经⽆法满⾜业务的增⻓，此时我们就需要进⾏微服务化的改造，降低业务的耦合度，提升开发迭代的效率，让开发更加敏捷。这⼀阶段我们聚焦以应⽤为核⼼。

#### 服务治理

​	当微服务的规模也越来越⼤的时候，如果对微服务不加以规范和整治，很容易出现问题。例如，每个微服务都有独⽴的团队来维护，他们之间如果依赖没有整理清楚，可能会出现架构上循环依赖等问题。从我们的数据观察来看，当微服务的节点数超过数⼗个的情况下，我们通常就需要引⼊服务治理，通常需要关注的是开发，测试，线上运维，安全等多⽅⾯考虑，这⼀阶段我们聚焦以业务为核⼼，核⼼⽬标是进⼀步提⾼开发效率，提⾼线上业务的稳定性。

### 微服务治理在云原⽣下的挑战

#### 在效率上⾯临的挑战

* 在开发阶段，我们需要考虑的是，业务应⽤上云之后，如何让本地开发的应⽤，很好的部署云上的业务进⾏联调？通常我们的微服务不可能在本地完整的部署⼀整套系统，所以本地开发的应⽤只是整个微服务链路的⼀⼩部分，这包括我们的流量需要能够轻松的从云上，引导到本地，便于我们做开发调试，或者我们在本地能够很⽅便的调⽤云上部署的微服务进⾏联调。这在微服务上云之后，变的⽐原来在⾃身机房进⾏开发联调更加困难。

* 在线上运维⽅⾯，我们通常需要频繁的对微服务进⾏变更，这些变更通常就会引发⼀系列的问题，例如在⽩天⾼峰期做发布，通常都会导致业务流量出现损失，我们的研发⼈员不得不选择在晚上业务低峰期做变更，这⼤⼤降低了研发⼈员的幸福指数，因为他们不得不⾯临熬夜加班的困境。如果能在⽩天⼤流量⾼峰期也能进⾏流量⽆损的变更，那么这对于研发⼈员来说将是⼤⼤提升研发效率的事情。

* 微服务框架通常会引⼊服务治理的逻辑，⽽这些逻辑通常会以SDK 的⽅式被业务代码所依赖，⽽这些逻辑的变更和升级，都需要每⼀个微服务业务通过修改代码的⽅式来实现，这样的变更造成了⾮常⼤的升级成本。以阿⾥巴巴为例，阿⾥内部⼀个中间件SDK 的升级，如果要在整个集团铺开，通常需要消耗的时间以年为单位进⾏统计，这⾥⾯也会消耗每个微服务应⽤的研发，测试等庞⼤的资源，效率⾮常低下，如果能够以⽆侵⼊的⽅式实现中间件SDK的升级，那么将会是⼀件⾮常⾼效的事情。

* 进⼊云原⽣体系之后，以K8s 为主的云原⽣体系强调集群之间的灵活调度型，以POD 为单位任意的调度资源，在被调度后POD 的IP 也将相应的发⽣变化，传统的服务治理体系，通常以IP 为维度进⾏治理策略的配置，例如⿊⽩名单策略等，但是当进⼊云原⽣场景后，这些传统的治理策略都会⾯临失效的问题，因为POD ⼀旦被重新调度，原来的治理策略都将不再使⽤，如何能让服务治理体系更加适应云原⽣体系，也是我们要⾯临的⼀⼤挑战。

#### 在稳定上⾯临的挑战

​	稳定⼤于⼀切，在微服务上云之后，业务⾼可⽤是我们必须要解决的问题，因此通常会在同⼀个地域的多个可⽤区内进⾏部署，在多可⽤区部署的情况下，跨可⽤区的延时就是不可忽视的问题，我们需要思考的是业务流量需要能够尽量在同⼀个可⽤区内进⾏流转，同时也需要考虑的是如果⼀个可⽤区出现问题，业务流量能够尽可能快的流转到正常的可⽤区，这就对我们的微服务框架的路由能⼒提出了挑战。

​	当然，我们的业务不仅需要在同⼀个地域⾥保证⾼可⽤，也需要考虑⼀个地域出问题的时候，保证业务的⾼可⽤，这时我们就需要考虑业务实现同城双活，甚⾄是异地多活，这对我们来说也是⼀⼤挑战。

​	第三，微服务之间的调⽤也需要更加的安全可信，近期层出不穷的安全漏洞，⼀定程度上也反应出当前上云阶段在安全⽅便暴露出的问题还是⾮常多，每次安全漏洞出现之后，中间件SDK的升级也是困扰业务多年的问题；同时，⼀些敏感的数据，即使在数据库层做了⾮常多的权限管控，由于微服务被授予了数据访问的较⾼权限，如果微服务的调⽤被恶意攻击，也可能会造成敏感数据的泄露。微服务之间的调⽤需要更加可靠可信。

#### 在成本上⾯临的挑战

​	⾸先，在成本⽅⾯，业务上云遇到的最大问题就是如何最低成本的把业务迁移上云，对于⼀个在线业务，如果要进⾏停机迁移，那么迁移的成本会显得⾮常⾼，对于客户的体验也会收到影响，要在不中断业务的情况下，实现平滑迁移上云，还是有⾮常⼤的挑战的。

### 1.3 微服务治理的发展趋势

随着云计算的不断发展和云原⽣理念的⼴泛传播，下⼀代微服务也带来了其他的挑战和机遇，微服务的发展有着以下趋势：

​	1.K8s 成为资源调度的事实标准，Service Mesh 从提出到发展⾄今已经逐渐被越来越多⽤户所接受。屏蔽底层基础设施成为软件架构的⼀个核⼼演进⽬标，⽆论是阿⾥巴巴还是其他企业⽤户，所⾯临的问题都已经从是否上云变为如何平滑稳定地低成本迁移上云。

​	2.由于上云路径的多样以及由现有架构迁移⾄云原⽣架构的过渡态存在，部署应⽤的设施灵活异变，云上的微服务也呈现出多元化的趋势。跨语⾔、跨⼚商、跨环境的调⽤必然会催⽣基于开放标准的统⼀协议和框架，以满⾜互通需求。

​	3.端上对后台服务的访问呈爆炸性的趋势增⻓，应⽤的规模和整个微服务体系的规模都随之增⻓。

#### 开发态服务治理

* 服务契约：业务开服能够清晰的了解应用定义了哪些接口、每个接口的参数、以及接口的业务说明；便于开发者迅速了解应用。

* 服务调试：在微服务开发和运行时快速地对某个接口进行调试，而不需要经过手动编写测试代码，也不需要关心网络打通流程。
* 服务Mock：当某个接口尚未开发完成时，可以通过配置Mock 此接口的请求行为，返回预设的值，使得开发时不需要依赖于下游接口开发完成。

* 开发环境隔离：通过逻辑隔离的方式，为每一个正在开发的功能特性隔离出一个独立的环境，在低成本的前提下，划分出多个完整的独立环境，使得各功能特性的开发调试不会互相影响，提升开发迭代的效率。
* 端云互联：本地开发的微服务可以快速的访问云上的服务，云上的服务也能调用到本地开发的微服务。

#### 测试态服务治理

* 服务压测：微服务上线前快速发起压测，迅速了解微服务的容量是否偏离基线，确保新版的性能。

* ⾃动化回归：通过自动化的方式进行回归测试，自动发起测试并自动比对结果进行验证，无需人工重复测试，保障业务代码逻辑的正确性。
* 流量录制：将线上流量录制下来，自动生成测试用例进行回归测试，通过真实的请求丰富测试覆盖率，保障业务代码逻辑的正确性。
* 流量回放：将录制好的流量重新运行，验证当前的业务运行结果是否和录制好的请求的结果匹配。

### 运⾏态服务治理

运⾏态通常⼜分为3 个部分：发布态，安全态，⾼可⽤。

#### 发布态

* ⽆损下线：确保应用在发布、停止、扩容时，所有请求都不会被影响，确保微服务下线的过程中业务无损。
* ⽆损上线：应用刚启动时可能会存在一些资源未初始化完成、未预热完毕的情况，无损上线功能可以确保在这个场景下不影响业务。
* ⾦丝雀发布：满足特定流量特征的请求才会进入微服务的灰度节点，通过小流量验证微服务新版的逻辑是否符合预期。
* 全链路灰度：一个迭代的多个应用同时发布，希望经过灰度的上游流量只能达到下游的灰度节点，确保灰度流量只在灰度环境中流转。

#### 安全态

* 服务鉴权：保护敏感微服务，确保敏感服务只能被已授权的应用发起访问。
* 漏洞防护：开源框架通常会陆陆续续被发现许多漏洞，整体的升级成本很高，需要通过不升
  级框架的⽅式实现漏洞的防护。
* 配置鉴权：某些配置⽐较敏感，不希望任何微服务都有权限访问，控制只有受限的微服务才
  能访问。

#### ⾼可⽤

* 限流：针对超过阈值的流量进行限流控制，保障机器和整体业务的稳定性。
* 降级：在资源有限的情况下，针对某些不重要的请求返回预设的降级结果，把有限的资源让给重要的请求。
* 熔断：客户端访问后端服务不可用的情况下，返回固定异常或预定义的结果，避免引起业务异常，甚至雪崩。
* 离群实例摘除：在单个服务提供者节点持续不可用的情况下，在消费者侧摘除这个异常节点，保障业务的高可用。
* 同可⽤区优先路由：微服务多可用区部署的情况下，确保流量优先在同一个可用区内流转，降低业务的整体时延。
* 就近容灾路由：当某个可⽤区发⽣故障，可以把流量尽快的切到正常的可⽤区，让业务以最快速度恢复。