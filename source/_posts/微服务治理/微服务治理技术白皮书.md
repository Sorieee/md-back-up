# 1. 综述

## 1.1 业务发展离不开微服务治理保驾护航

### 业务快速发展期

**1.开发测试提效**

a.【开发环境隔离】传统的多套开发环境，需要使⽤多套的物理环境，才能实现多套环境各⾃独⽴互不⼲扰，但是多套物理环境的隔离的机器成本是很⾼的，基本上不⼤能接受。但通过全链路灰度这种逻辑隔离的⽅式实现开发环境隔离，可以在不增加成本的情况下增加多套开发测试环境，助你实现敏捷开发。

b.【⾃动化回归测试】⾃动化回归测试功能，可以将多个测试⽤例串联成测试⽤例集，将上⼀条测试的返回值作为下⼀跳测试⼊参，串联成具体的业务场景并沉淀到⾃动化回归测试中，在每⼀次的发版之前都跑⼀次⾃动化回归来验证功能的正确性，这样就可以⼤⼤节省测试的⼈⼒成本。更进⼀步，还可以通过流量录制回放功能，将线上的真实流量录制下来，并沉淀成⾃动化回归⽤例集，在测试环境进⾏流量回放，更进⼀步地提升测试case 的覆盖率。

c.【服务契约】功能越来越多，迭代越来越快，API 越来越复杂，团队之间沟通的效率越来越低，API ⽂档严重过期。如果能⾃动⽣成服务契约，可以有效地避免⽂档腐化造成的开发效率低下的问题。

**2.安全发布**

a.【⽆损下线】⽆损下线问题的根本原因是开源的微服务体系没有确保应⽤提供者节点在停⽌服务前确保已经通知到所有消费者不再调⽤⾃⼰，也⽆法确保在处理完所有请求之后再停⽌应⽤。所以新发版的应⽤，即使业务代码没有任何问题，也可能在发布过程影响⽤户的体验。

b.【⽆损上线】⽆损上线问题出现的原因是因为在某些场景下服务提供者，需要经过⼀段时间才能正常地接收⼤流量的请求并成功返回。同时在K8s 场景下，还需要和K8s 中的readiness 、滚动发布等⽣命周期紧密结合，才能确保应⽤发布过程中能不出现业务报错。

c.【全链路灰度】新功能上线之后，可以通过灰度规则控制哪些⽤户可以使⽤。这样可以先选择让内部⽤户使⽤，测试新功能的正确性。当内部⽤户验证通过后，再渐渐地扩⼤灰度范围，确保每个功能都经过充分验证后再全量开放给客户，屏蔽掉发布新功能的⻛险。⽽且当出现问题时，可以通过修改灰度规则来实现快速回滚，做到新版本发版时⼏乎⽆⻛险。

**3.屏蔽偶发异常导致的⻛险**

a.【离群实例摘除】对于这些偶发的异常问题，离群摘除功能可以智能判断应⽤中的服务提供者某个出现了问题，智能地在⼀段时间内屏蔽掉这个服务提供者，保证业务的正常，等这个服务提供者恢复过来之后再进⾏调⽤。可以在应⽤节点出现偶发异常时，智能屏蔽掉此节点，以免影响业务，等此节点恢复后再继续提供服务，从⽽屏蔽偶发异常导致的⻛险。

​	据统计数据显示，有将近90%的线上故障是由于发版过程中出现的，剩下的10% 左右的线上问题，可能是由于⼀些偶然的原因导致的。⽐如偶然的⽹络故障、机器I/O 出现问题、或者是某台机器负载过⾼等。在解决了发布时候的稳定性问题和偶发异常导致的⻛险后，基本能够确保线上业务不会出现灾难性的问题。

### 业务成熟期

​	低成本创新：虽然发展不像原来那么迅速，但是业务创新探索的诉求仍旧存在，由于业务规模的扩⼤，创新的成本也在增加。这个时候不仅是需要快速开发迭代，更⼤的需求是⽤尽可能⼩的成本进⾏创新探索测试，有时候还需要使⽤上AB 测试的⼿段进⾏实验⽐较。

​	容灾多活：由于业务规模已经很⼤了，治理中的稳定性的诉求更加强烈，⽽且随着业务范围的扩⼤，应⽤也开始在多个地域、多个云产品中进⾏部署。同城容灾、异地多活这类需求也开始出现。

​	问题定位：出现任何问题都必须彻查。虽然出现问题时，业务恢复仍旧排查第⼀位，但是业务恢复之后的问题根因定位也是不能少的，因为如果不彻查，难免后续出现同样的问题。

​	⻛险预案：紧急预案、⻛险预防也变得⾮常重要，需要提前做好业务的保护和降级的埋点演练，在遇到绝⼤多数可预⻅问题可以紧急修复，出现不可控问题时，可以通过预案⼿段执⾏预案，确保整体业务的可控性。

## 1.2 微服务治理在云原⽣场景下的挑战

​	我们分析了阿⾥云典型客户的实践经历，业务上云通常划分为4 个阶段：云上部署、云原⽣部署、微服务化、服务治理。

![](https://pic.imgdb.cn/item/62a601de09475431299b9c82.jpg)

#### 云上部署

​	这⼀阶段我们解决的问题，如何把传统业务，原来是跑在⾃建IDC 机房的业务，能够原封不动的迁移到云上。通常云⼚商提供了丰富的计算，存储，⽹络等资源可供选择，以虚拟化技术，神⻰裸⾦属服务为代表的硬件可以满⾜企业客户上云搬迁的丰富需求，这⼀阶段关注的焦点是资源，对于业务并⽆任何的改造，只需要从本地原样搬迁到云上即可。

#### 云原⽣部署

​	云原⽣是释放云计算价值的最短路径，以容器技术为代表，云原⽣提供了强⼤的调度，弹性等能⼒，极⼤的降低了上云的成本。这⼀阶段我们关注的⽬标主要是业务进⾏云原⽣化改造，随着Kubernetes 作为容器编排市场的事实标准，我们需要把业务从原来的的虚拟机部署⽅式改造成容器化⽅式，部署并运⾏在K8s 之上，最⼤限度享受到云原⽣带来的技术红利。这⼀阶段核⼼关注⽬标以容器为核⼼。

#### 微服务化

​	当我们的业务规模逐步扩⼤，传统单体应⽤很难进⼀步⽀撑业务的发展，业务的迭代速度已经⽆法满⾜业务的增⻓，此时我们就需要进⾏微服务化的改造，降低业务的耦合度，提升开发迭代的效率，让开发更加敏捷。这⼀阶段我们聚焦以应⽤为核⼼。

#### 服务治理

​	当微服务的规模也越来越⼤的时候，如果对微服务不加以规范和整治，很容易出现问题。例如，每个微服务都有独⽴的团队来维护，他们之间如果依赖没有整理清楚，可能会出现架构上循环依赖等问题。从我们的数据观察来看，当微服务的节点数超过数⼗个的情况下，我们通常就需要引⼊服务治理，通常需要关注的是开发，测试，线上运维，安全等多⽅⾯考虑，这⼀阶段我们聚焦以业务为核⼼，核⼼⽬标是进⼀步提⾼开发效率，提⾼线上业务的稳定性。

### 微服务治理在云原⽣下的挑战

#### 在效率上⾯临的挑战

* 在开发阶段，我们需要考虑的是，业务应⽤上云之后，如何让本地开发的应⽤，很好的部署云上的业务进⾏联调？通常我们的微服务不可能在本地完整的部署⼀整套系统，所以本地开发的应⽤只是整个微服务链路的⼀⼩部分，这包括我们的流量需要能够轻松的从云上，引导到本地，便于我们做开发调试，或者我们在本地能够很⽅便的调⽤云上部署的微服务进⾏联调。这在微服务上云之后，变的⽐原来在⾃身机房进⾏开发联调更加困难。

* 在线上运维⽅⾯，我们通常需要频繁的对微服务进⾏变更，这些变更通常就会引发⼀系列的问题，例如在⽩天⾼峰期做发布，通常都会导致业务流量出现损失，我们的研发⼈员不得不选择在晚上业务低峰期做变更，这⼤⼤降低了研发⼈员的幸福指数，因为他们不得不⾯临熬夜加班的困境。如果能在⽩天⼤流量⾼峰期也能进⾏流量⽆损的变更，那么这对于研发⼈员来说将是⼤⼤提升研发效率的事情。

* 微服务框架通常会引⼊服务治理的逻辑，⽽这些逻辑通常会以SDK 的⽅式被业务代码所依赖，⽽这些逻辑的变更和升级，都需要每⼀个微服务业务通过修改代码的⽅式来实现，这样的变更造成了⾮常⼤的升级成本。以阿⾥巴巴为例，阿⾥内部⼀个中间件SDK 的升级，如果要在整个集团铺开，通常需要消耗的时间以年为单位进⾏统计，这⾥⾯也会消耗每个微服务应⽤的研发，测试等庞⼤的资源，效率⾮常低下，如果能够以⽆侵⼊的⽅式实现中间件SDK的升级，那么将会是⼀件⾮常⾼效的事情。

* 进⼊云原⽣体系之后，以K8s 为主的云原⽣体系强调集群之间的灵活调度型，以POD 为单位任意的调度资源，在被调度后POD 的IP 也将相应的发⽣变化，传统的服务治理体系，通常以IP 为维度进⾏治理策略的配置，例如⿊⽩名单策略等，但是当进⼊云原⽣场景后，这些传统的治理策略都会⾯临失效的问题，因为POD ⼀旦被重新调度，原来的治理策略都将不再使⽤，如何能让服务治理体系更加适应云原⽣体系，也是我们要⾯临的⼀⼤挑战。

#### 在稳定上⾯临的挑战

​	稳定⼤于⼀切，在微服务上云之后，业务⾼可⽤是我们必须要解决的问题，因此通常会在同⼀个地域的多个可⽤区内进⾏部署，在多可⽤区部署的情况下，跨可⽤区的延时就是不可忽视的问题，我们需要思考的是业务流量需要能够尽量在同⼀个可⽤区内进⾏流转，同时也需要考虑的是如果⼀个可⽤区出现问题，业务流量能够尽可能快的流转到正常的可⽤区，这就对我们的微服务框架的路由能⼒提出了挑战。

​	当然，我们的业务不仅需要在同⼀个地域⾥保证⾼可⽤，也需要考虑⼀个地域出问题的时候，保证业务的⾼可⽤，这时我们就需要考虑业务实现同城双活，甚⾄是异地多活，这对我们来说也是⼀⼤挑战。

​	第三，微服务之间的调⽤也需要更加的安全可信，近期层出不穷的安全漏洞，⼀定程度上也反应出当前上云阶段在安全⽅便暴露出的问题还是⾮常多，每次安全漏洞出现之后，中间件SDK的升级也是困扰业务多年的问题；同时，⼀些敏感的数据，即使在数据库层做了⾮常多的权限管控，由于微服务被授予了数据访问的较⾼权限，如果微服务的调⽤被恶意攻击，也可能会造成敏感数据的泄露。微服务之间的调⽤需要更加可靠可信。

#### 在成本上⾯临的挑战

​	⾸先，在成本⽅⾯，业务上云遇到的最大问题就是如何最低成本的把业务迁移上云，对于⼀个在线业务，如果要进⾏停机迁移，那么迁移的成本会显得⾮常⾼，对于客户的体验也会收到影响，要在不中断业务的情况下，实现平滑迁移上云，还是有⾮常⼤的挑战的。

## 1.3 微服务治理的发展趋势

随着云计算的不断发展和云原⽣理念的⼴泛传播，下⼀代微服务也带来了其他的挑战和机遇，微服务的发展有着以下趋势：

​	1.K8s 成为资源调度的事实标准，Service Mesh 从提出到发展⾄今已经逐渐被越来越多⽤户所接受。屏蔽底层基础设施成为软件架构的⼀个核⼼演进⽬标，⽆论是阿⾥巴巴还是其他企业⽤户，所⾯临的问题都已经从是否上云变为如何平滑稳定地低成本迁移上云。

​	2.由于上云路径的多样以及由现有架构迁移⾄云原⽣架构的过渡态存在，部署应⽤的设施灵活异变，云上的微服务也呈现出多元化的趋势。跨语⾔、跨⼚商、跨环境的调⽤必然会催⽣基于开放标准的统⼀协议和框架，以满⾜互通需求。

​	3.端上对后台服务的访问呈爆炸性的趋势增⻓，应⽤的规模和整个微服务体系的规模都随之增⻓。

## 1.4 微服务治理的区分

#### 开发态服务治理

* 服务契约：业务开服能够清晰的了解应用定义了哪些接口、每个接口的参数、以及接口的业务说明；便于开发者迅速了解应用。

* 服务调试：在微服务开发和运行时快速地对某个接口进行调试，而不需要经过手动编写测试代码，也不需要关心网络打通流程。
* 服务Mock：当某个接口尚未开发完成时，可以通过配置Mock 此接口的请求行为，返回预设的值，使得开发时不需要依赖于下游接口开发完成。

* 开发环境隔离：通过逻辑隔离的方式，为每一个正在开发的功能特性隔离出一个独立的环境，在低成本的前提下，划分出多个完整的独立环境，使得各功能特性的开发调试不会互相影响，提升开发迭代的效率。
* 端云互联：本地开发的微服务可以快速的访问云上的服务，云上的服务也能调用到本地开发的微服务。

#### 测试态服务治理

* 服务压测：微服务上线前快速发起压测，迅速了解微服务的容量是否偏离基线，确保新版的性能。

* ⾃动化回归：通过自动化的方式进行回归测试，自动发起测试并自动比对结果进行验证，无需人工重复测试，保障业务代码逻辑的正确性。
* 流量录制：将线上流量录制下来，自动生成测试用例进行回归测试，通过真实的请求丰富测试覆盖率，保障业务代码逻辑的正确性。
* 流量回放：将录制好的流量重新运行，验证当前的业务运行结果是否和录制好的请求的结果匹配。

### 运⾏态服务治理

运⾏态通常⼜分为3 个部分：发布态，安全态，⾼可⽤。

#### 发布态

* ⽆损下线：确保应用在发布、停止、扩容时，所有请求都不会被影响，确保微服务下线的过程中业务无损。
* ⽆损上线：应用刚启动时可能会存在一些资源未初始化完成、未预热完毕的情况，无损上线功能可以确保在这个场景下不影响业务。
* ⾦丝雀发布：满足特定流量特征的请求才会进入微服务的灰度节点，通过小流量验证微服务新版的逻辑是否符合预期。
* 全链路灰度：一个迭代的多个应用同时发布，希望经过灰度的上游流量只能达到下游的灰度节点，确保灰度流量只在灰度环境中流转。

#### 安全态

* 服务鉴权：保护敏感微服务，确保敏感服务只能被已授权的应用发起访问。
* 漏洞防护：开源框架通常会陆陆续续被发现许多漏洞，整体的升级成本很高，需要通过不升
  级框架的⽅式实现漏洞的防护。
* 配置鉴权：某些配置⽐较敏感，不希望任何微服务都有权限访问，控制只有受限的微服务才
  能访问。

#### ⾼可⽤

* 限流：针对超过阈值的流量进行限流控制，保障机器和整体业务的稳定性。
* 降级：在资源有限的情况下，针对某些不重要的请求返回预设的降级结果，把有限的资源让给重要的请求。
* 熔断：客户端访问后端服务不可用的情况下，返回固定异常或预定义的结果，避免引起业务异常，甚至雪崩。
* 离群实例摘除：在单个服务提供者节点持续不可用的情况下，在消费者侧摘除这个异常节点，保障业务的高可用。
* 同可⽤区优先路由：微服务多可用区部署的情况下，确保流量优先在同一个可用区内流转，降低业务的整体时延。
* 就近容灾路由：当某个可⽤区发⽣故障，可以把流量尽快的切到正常的可⽤区，让业务以最快速度恢复。

# 2. 微服务治理技术原理介绍

## 2.1 微服务治理技术概述

**第⼀阶段： ⾃研微服务**
	阿⾥巴巴的微服务拆分实践进⾏的很早，从2008 年就开始了，当时的单体应⽤已经⽆法承载业务迭代的速度，由五彩⽯项⽬开始了微服务化的改造，在这个改造过程中，也逐步诞⽣了服务框架，消息队列，数据库分库分表等三⼤中间件。在这个阶段的服务治理能⼒是通过SDK⽅式直接依赖在框架⾥⾯的。每个中间件都有⾃⼰独⽴的SDK 依赖，服务治理能⼒的升级需要借助框架SDK 的升级来解决，升级成本是很⾼的。

**第⼆阶段：Fat-SDK**

​	随着中间件接⼊数量的增加，业务升级成本不断攀升，从2013 年起诞⽣了代号“Pandora”的项⽬，主要有2 个⽬标，⼀是解决中间件和业务依赖的冲突问题，⼆是解决服务治理升级效率的问题。同⼀个组件，业务和中间件的可能依赖不同的版本，最常⻅的例如⽇志，序列化组件等等，如果⼤家共享⼀个版本则会出现中间件的升级影响到业务，或者出现不兼容的情况。Pandora 提供了⼀个轻量的隔离容器，通过类加载器隔离的⽅式，将中间件和业务的依赖互相隔离，⽽中间件和中间件之间的依赖也能互相隔离。另外，通过Fat-SDK 的⽅式，将所有中间件⼀次性打包交付给业务⽅升级。这⼀点和Maven 引⼊的bom 的思路类似，但是相⽐bom 来说每个Pandora 的插件都可以享有独⽴的依赖。通过这种⽅式，业务不再需要单独升级某个中间件，⽽是⼀次性把所有的中间件完成升级，从⽽⼤幅提升了中间件升级的效率。

**第三阶段：One Java Agent**

​	随着业务的进⼀步发展，中间件的数量逐步增加，Pandora 的⽅式也遇到了相当多的问题，也就是如果要把⼀个Pandora 的版本在全集团内全部推平，需要⻓达1 年的时间才能完成。这是因为即使是Pandora 的⽅式，也需要业务修改代码，升级，验证，发布，这些并⾮业务真正关⼼，业务更希望专注于⾃身业务的发展。通常借助双⼗⼀⼤促这样的机会，才有可能完成中间件的升级。这也给服务治理的形态带来新的挑战。2019 年，阿⾥推出了One Java Agent 的形态，把服务治理的能⼒下沉到Java Agent 的形式，通过⽆侵⼊的⽅式，实现了中间件的迭代升级，进⼀步提升了升级效率。

**第四阶段：One Mesh**

​	Java Agent 通常只能解决Java 语⾔构建的微服务，针对⾮Java 语⾔构建的微服务体系，阿⾥也借助Service Mesh 的⽅式，把服务治理能⼒下沉到sidecar，实现了和业务的解耦。通过sidecar 的⽅式，不同语⾔的能⼒⽆需重复开发，sidecar 的升级也可以做到透明，对业务⽆感。值得注意的是，⽆论是SDK 的形态，还是Agent 的形态，还是sidecar 的形态，对于服务治理的控制台来说，都需要统⼀的控制面对多种数据⾯进⾏控制。

## 2.2 通过SDK ⽅式进⾏微服务治理

### 独立SDK 模式

![](https://pic.imgdb.cn/item/62aae1840947543129ce16ef.jpg)

### Fat-SDK 模式

​	通过单一SDK 提供服务治理能力后，各个SDK 的提供方需要对提供出去的SDK 进行支持，需要及时替换、升级旧版本的SDK，并及时督促SDK 使用方进行升级。

![](https://pic.imgdb.cn/item/62aae43b0947543129d28804.jpg)

## 2.3 通过Java Agent ⽅式进⾏微服务治理

​	中间件作为提供⽅，苦于业务⽅不能及时升级中间件到最新版。业务⽅作为使⽤⽅，苦于升级成本⽐较⾼

### Java Agent 技术

​	在JVM 启动的时候，可以通过-javaagent:/path/to/agent.jar 的⽅式来加载Java Agent。在Java Agent 中，实现ClassFileTransformer 接⼝，并调⽤Instrumentation.addTransformer将Transformer 添加到系统中。

​	基于ClassFileTransformer 能⼒，中间件只需要提供⼀个标准的轻量级SDK，提供简单实现和接⼝；剩余的⽐较重的逻辑，就可以写在Java Agent 中，通过ClassFileTransformer 的⽅式动态插⼊到Java 代码中。

### One Java Agent

​	中间件分为很多不同的部分，⽐如RPC、消息、数据库等。中间件内部也需要⼀些机制来保证
Java Agent 中各个中间件的代码能够独⽴开发、部署，且尽可能做到互不影响。

​	所以阿⾥云内部将各个中间件的Java Agent 作为插件(plugin)，组装成⼀个统⼀的Java Agent，称为One Java Agent。

每个plugin 可以由启动参数来单独控制是否开启。

* 各个plugin 的启动是并⾏的，将Java Agent 的启动速度由O(n+m+...)提升⾄O(n)。
* 各个plugin 的类，都由不同的类加载器加载，最⼤限度隔离了各个plugin。
* 每个plugin 的状态都可以上报到服务端，可以通过监控来检测各个plugin 是否有问题。

![](https://pic.imgdb.cn/item/62aae4d10947543129d36981.jpg)

⽬前One Java Agent 项⽬已经开源：https://github.com/alibaba/one-java-agent。

### 云原⽣场景下如何⾃动注⼊Java Agent

​	对于Java Agent，需要业务容器启动的时候给Java 命令⾏添加启动参数`-javaagent:<jarpat
h> [=<options>]`，这需要重新构建容器镜像。对于⼤规模的业务统⼀接⼊，需要重新构建全部
容器镜像。这对于运维来说是及其繁琐的事情。因此我们需要⼀种⽅式，能够将⾃动注⼊
Java Agent 与⽣成容器镜像进⾏解耦。

​	⽽Java 提供了JAVA_TOOL_OPTIONS 环境变量：在JVM 启动时，JVM 会读取并应⽤此环境变量的值，这样我们就可以通过在容器镜像中设置环境变量：`JAVA_TOOL_OPTIONS=-javaagent:/path/to/agent.jar` ，从⽽实现不⽤修改镜像，就可以加载Java Agent 了。

​	在Kubernetes 环境中，我们可以借助webhook 能⼒，来实现⾃动注⼊JAVA_TOOL_OPTIONS ，从⽽达到⾃动开启服务治理的功能。

​	配置Webhook，然后根据Pod 或者Namespace 中的Labels，来判断是否要挂载Java Agent。如果需要挂载，则就对Pod 的声明⽂件做出如下修改：

* 获取并添加环境变量JAVA_TOOL_OPTIONS，⽤于加载Java Agent。
* 给业务容器添加Volume，⽤于存储Java Agent 的⽂件内容。
* 给Pod 添加Init container，⽤于在业务容器启动前下载Java Agent。

​	最终，我们将此功能模块提供为Helm 包，运维⼈员可以⼀键安装。如果要接⼊服务治理，也只需要给对应资源添加label 即可接⼊。

## 2.4 通过Service Mesh 来进⾏微服务治理

Service Mesh 的出现，为异构微服务体系治理打开了⼀种全新的思路。

* 2016 年可以说是Service Mesh 的元年，Buoyant 公司CEO William Morgan 率先发布
  Linkerd ，成为业界⾸个Service Mesh 项⽬，同年Lyft 发布Envoy ，成为第⼆个
  Service Mesh 项⽬。
* 2017 年，Google、IBM、Lyft 联⼿发布了Istio，它与Linkerd / Envoy 等项⽬相⽐，它⾸
  次给⼤家增加了控制平⾯的概念，提供了强⼤的流量控制能⼒。经过多年的发展Istio，已经
  逐步成为控制平⾯的事实标准。
* 1.0 版本的问世标志着Istio 进⼊了可以⽣产可⽤的时代，越来越多的企业将服务⽹格应⽤于
  ⽣产中。
* 1.5 版本开始将原有的多个组件整合为⼀个单体结构istiod；同时废弃了被诟病已久的
  Mixer 组件，统⼀为Istiod 服务，⽅便部署和运维。

### Istio 的架构

![](https://pic.imgdb.cn/item/62aae5fa0947543129d51dfc.jpg)

​	Istiod 作为控制⾯的统⼀组件，负责对接服务注册发现、路由规则管理、证书管理等能⼒，Envoy Proxy 作为数据⾯Sidecar 代理业务流量，Istio 和Envoy Proxy 之间通过XDS 接⼝完成服务发现、路由规则等数据的传递，同时Istio 也提供了MCP Over XDS 接⼝对接外部注册中⼼，如Nacos。

​	Istio 除了⽀持东⻄向的流量代理之外，还⽀持的代理，通过Istio Ingress Gateway作为⼊⼝的⽹关，通过Istio Egress Gateway 作为出⼝⽹关，这样Istio 将可以对全域流量进⾏治理。

![](https://pic.imgdb.cn/item/62aae62a0947543129d561a5.jpg)

​	在云原⽣微服务治理中提供了基于ASM Istio 的服务治理能⼒，包含标签路由、服务鉴权、故障注⼊、⾦丝雀发布、服务测试、⽆损上下线等。

![](https://pic.imgdb.cn/item/62aae65f0947543129d5aff4.jpg)

### 流量劫持能⼒

​	iptables 是Linux 内核中的防⽕墙软件netfilter 的管理⼯具，位于⽤户空间，同时也是netfilter 的⼀部分。Netfilter 位于内核空间，不仅有⽹络地址转换的功能，也具备数据包内容修改、以及数据包过滤等防⽕墙功能。

​	在kubernetes 的⽅案中，Istio 会在开启了Sidecar 注⼊标记的Pod 中注⼊⼀个Init Container 和⼀个普通容器istio-proxy，Init Container 容器会执⾏⼀段iptables 脚本，根据脚本的参数，将Inbound 和OutBound 流量都导⼊到Envoy 指定的端⼝上，Istio-Proxy 容器由2 个进程组成，Pilot Agent 会⽤来获取Envoy 的启动配置，然后创建⼀个Envoy 的进程，同时会对Envoy 进程进⾏健康检查。

![](https://pic.imgdb.cn/item/62aae6e70947543129d69050.jpg)

### 基于eBPF 流量劫持能⼒

​	由于eBPF 技术的兴起，在可观测性和⽹络包的处理上有了不少优秀的实践，像Cilium 被⼤家所熟知，使⽤eBPF 的sockops 和redir 等能⼒，可以⾼效地处理数据包。

​	使⽤iptables 的技术，需要对出⼊⼝都拦截，会让原本只需在内核态处理两次的链路，变成四次，造成⼤量的性能损失，这对⼀些性能要求⾼的场景有明显的影响。相⽐于基于iptables 的流量劫持技术，基于eBPF 的技术可以将应⽤发出的包直接转发到对端的socket，加速包在内核中的处理流程。

​	eBPF 在做流量劫持的过程，针对出⼝流量，需要修改连接的⽬的地址，发送到新的端⼝，同时要记住之前的⽬的地址，这样便于Envoy 将流量进⾏转发，针对⼊⼝流量也是类似的，只是需要将劫持到的Envoy 端⼝修改为15006 端⼝。

### 流量路由过程

流量路由分为Inbound 和Outbound 两个过程，Inbound 即为进⼊Pod 的流量，OutBound即为Pod 访问出去的流量，以下将描述流量的处理流程：

​	Inbound handler 的作⽤是将iptables 拦截到的downstream 的流量转交给localhost，与Pod 内的应⽤程序容器建⽴连接，可以通过访问15000 的admin 接⼝查看业务Pod 的Listener 列表，从中可以看到0.0.0.0:15006/TCP 的Listener（其实际名字是virtualInbound）监听所有的Inbound 流量，Inbound handler 的流量被virtualInbound Listener 转移到Pod 的指定端⼝的Listener，然后找到对应的Cluster 和Endpoint 进⾏转发，这样流量顺利到达业务容器指定的端⼝。

​	Outbound handler 的作⽤是将iptables 拦截到的本地应⽤程序发出的流量，经由sidecar判断如何路由到upstream。应⽤程序容器发出的请求为Outbound 流量，被iptables 劫持后转移给Outbound handler 处理，然后经过virtualOutbound Listener、服务端对应端⼝的Listener，然后通过Route 指定的端⼝号找到upstream 的cluster，进⽽通过EDS 找到Endpoint 执⾏路由动作。

### 基于Envoy Filter 的服务治理

​	Istio 通过Sidecar 将服务治理的能⼒进⾏了标准化和统⼀化，⽐如故障注⼊、⾦丝雀发布、负载均衡、服务鉴权，同时还提供了可观测的能⼒，如Metrics、⽇志。

# 3. 微服务治理在云原⽣场景下的解决⽅案

## 3.1 线上发布稳定性解决⽅案

### ⽆损上下线背景

常见的流量有损现象出现的原因包括但不限于以下⼏种：

* 服务⽆法及时下线：服务消费者感知注册中⼼服务列表存在延时，导致应⽤特定实例下线后在⼀段时间内服务消费者仍然调⽤已下线实例造成请求报错。
* 初始化慢：应⽤刚启动接收线上流量进⾏资源初始化加载，由于流量太⼤，初始化过程慢，出现⼤量请求响应超时、阻塞、资源耗尽从⽽造成刚启动应⽤宕机。
* 注册太早：服务存在异步资源加载问题，当服务还未初始化完全就被注册到注册中⼼，导致调⽤时资源未加载完毕出现请求响应慢、调⽤超时报错等现象。
* 发布态与运⾏态未对⻬：使⽤Kubernetes 的滚动发布功能进⾏应⽤发布，由于Kubernetes的滚动发布⼀般关联的就绪检查机制，是通过检查应⽤特定端⼝是否启动作为应⽤就绪的标志来触发下⼀批次的实例发布，但在微服务应⽤中只有当应⽤完成了服务注册才可对外提供服务调⽤。因此某些情况下会出现新应⽤还未注册到注册中⼼，⽼应⽤实例就被下线，导致⽆服务可⽤。

### ⽆损下线

![](https://pic.imgdb.cn/item/62aaea8d0947543129dca3cf.jpg)

本节将对业界应用于云原生场景中的一些无损下线技术方案进行介绍。

#### 主动通知

​	一般注册中心都提供了主动注销接口供微服务应用正常关闭时调用，以便下线实例能及时更新其在注册中心上的状态。主动注销在部分基于事件感知注册中心服务列表的微服务框架比如Dubbo 中能及时让上游服务消费者感知到提供者下线避免后续调用已下线实例。但对于像Spring Cloud 这类微服务框架服务消费者感知注册中心实例变化是通过定时拉取服务列表的方式实现。尽管下线实例通过注册中心主动注销接口更新了其自身在注册中心上的应用状态信息但由于上游消费者需要在下一次拉取注册中心应用列表时才能感知到，因此会出现消费者感知注册中心实例变化存在延时。在流量较大、并发较高的场景中，当实例下线后，仍无法实现流量无损。既然无法通过注册中心让存量消费者实例实时感知下游服务提供者的变化情况，业界提出了利用主动通知解决该类问题

![](https://pic.imgdb.cn/item/62aaebed0947543129e0029c.jpg)

#### ⾃适应等待

​	在并发度不⾼的场景下，主动通知⽅法可以解决绝⼤部分应⽤下线流量有损问题。但对于⾼并发⼤流量应⽤下线场景，如果主动通知完，可能仍然存在⼀些在途请求需要待下线应⽤处理完才能下线否则这些流量就⽆法正常被响应。为解决该类在途请求问题，可通过给待下线应⽤在下线前通过⾃适应等待机制在处理完所有在途请求后，再下线以实现流量⽆损。

![](https://pic.imgdb.cn/item/62aaec230947543129e081d9.jpg)

### ⽆损上线

​	延迟加载是软件框架设计过程中最常⻅的⼀种策略，例如在Spring Cloud 框架中Ribbon 组件的拉取服务列表初始化默认都是要等到服务的第⼀次调⽤时刻，例如下图4 是Spring Cloud 应⽤中第⼀次和第⼆次通过调⽤RestTemplate 调⽤远程服务的耗时对比情况：

​	第⼀次调⽤由于进⾏了⼀些资源初始化，耗时是正常情况的数倍之多。因此把新应⽤发布到线上直接处理⼤流量极易出现⼤量请求响应慢，资源阻塞，应⽤实例宕机的现象。

​	业界针对上述应⽤⽆损上线场景提出如下包括延迟注册、⼩流量服务预热以及就绪检查等⼀系列解决⽅案，详细完整的⽅案如下图5 所示：

![](https://pic.imgdb.cn/item/62aaec650947543129e12f14.jpg)

#### 延迟注册

​	对于初始化过程需要异步加载资源的复杂应⽤启动过程，由于注册通常与应⽤初始化过程同步进⾏，从⽽出现应⽤还未完全初始化就已经被注册到注册中⼼供外部消费者调⽤，此时直接调
⽤由于资源未加载完成可能会导致请求报错。通过设置延迟注册，可让应⽤在充分初始化后再注册到注册中⼼对外提供服务。例如开源微服务治理框架Dubbo 原⽣就提供延迟注册功能[1]。

#### ⼩流量服务预热

​	在线上发布场景下，很多时候刚启动的冷系统直接处理⼤量请求，可能由于系统内部资源初始化不彻底从⽽出现⼤量请求超时、阻塞、报错甚⾄导致刚发布应⽤宕机等线上发布事故出现。为了避免该类问题业界针对不同框架类型以及应⽤⾃身特点设计了不同的应对举措，⽐如针对类加载慢问题有编写脚本促使JVM 进⾏预热、阿⾥巴巴集团内部HSF（High Speed Framework）使⽤的对接⼝分批发布、延迟注册、通过mock 脚本对应⽤进⾏模拟请求预热以及⼩流量预热等。本节将对其中适⽤范围最⼴的⼩流量预热⽅法进⾏介绍。

![](https://pic.imgdb.cn/item/62aaecae0947543129e21e9d.jpg)

![](https://pic.imgdb.cn/item/62aaeccc0947543129e28062.jpg)

### 微服务就绪检查

#### Kubernetes 探针技术

​	在云原⽣领域，Kubernetes 为了确保应⽤Pod 在对外提供服务之前应⽤已经完全启动就绪或者应⽤Pod⻓时间运⾏期间出现意外后能及时恢复，提供了探针技术来动态检测应⽤的运⾏情况，为保证应⽤的⽆损上线和⻓时间健康运⾏提供了保障。

#### 存活探针

​	Kubernetes 中提供的存活探测器来探测什么时候进⾏容器重启。例如，存活探测器可以捕捉到死锁（应⽤程序在运⾏，但是⽆法继续执⾏后⾯的步骤）。在这样的情况下重启容器有助于让应⽤程序在有问题的情况下更可⽤。

#### 就绪探针

​	Kubernetes 中提供的就绪探测器可以知道容器什么时候准备好了并可以开始接受请求流量，当⼀个Pod 内的所有容器都准备好了，才能把这个Pod 看作就绪了。这种信号的⼀个⽤途就是控制哪个Pod 作为Service 的后端。在Pod 还没有准备好的时候，会从Service 的负载均衡器中被剔除的。

#### 启动探针

​	Kubernetes 中提供的启动探测器可以知道应⽤程序容器什么时候启动了。如果配置了这类探测器，就可以控制容器在启动成功后再进⾏存活性和就绪检查，确保这些存活、就绪探测器不会影响应⽤程序的启动。这可以⽤于对慢启动容器进⾏存活性检测，避免它们在启动运⾏之前就被杀掉。

#### 探针使⽤⼩结

1.当需要在容器已经启动后再执⾏存活探针或者就绪探针检查，则可通过设定启动探针实现。
2.当容器应⽤在遇到异常或不健康的情况下会⾃⾏崩溃，则不⼀定需要存活探针，Kubernetes
能根据Pod 的restartPolicy 策略⾃动执⾏预设的操作。
3.当容器在探测失败时被Kill 并重新启动，则可通过指定⼀个存活探针，并指定restartPolicy
为Always 或OnFailure。
4.当希望容器仅在探测成功时Pod 才开始接收外部请求流量，则可使⽤就绪探针。

Kubernetes 探针技术使⽤实例：
	https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-liveness-readinessstartup-probes/

## 3.2 微服务全链路灰度解决⽅案

### 什么是全链路灰度

#### 单体架构下的服务发布

![](https://pic.imgdb.cn/item/62aaef7e0947543129eaa358.jpg)

​	⽬前，业界已经有⾮常成熟的服务发布⽅案，例如蓝绿发布和灰度发布。蓝绿发布需要对服务的新版本进⾏冗余部署，⼀般新版本的机器规格和数量与旧版本保持⼀致，相当于该服务有两套完全相同的部署环境，只不过此时只有旧版本在对外提供服务，新版本作为热备。当服务进⾏版本升级时，我们只需将流量全部切换到新版本即可，旧版本作为热备。我们的例⼦使⽤蓝绿发布的示意图如下，流量切换基于四层代理的流量⽹关即可完成。

![](https://pic.imgdb.cn/item/62aaefc20947543129eb75c7.jpg)

![](https://pic.imgdb.cn/item/62ab0191094754312917fd6b.jpg)

#### 微服务架构下的服务发布

​	在分布式微服务架构中，应⽤中被拆分出来的⼦服务都是独⽴部署、运⾏和迭代的。单个服务新版本上线时，我们再也不需要对应⽤整体进⾏发版，只需关注每个微服务⾃身的发布流程即可，如下：

![](https://pic.imgdb.cn/item/62ab028d09475431291a6758.jpg)

* 基于Provider 的治理策略。配置Cart 的流量流⼊规则，User 路由到Cart 时使⽤Cart 的流量流⼊规则。
* 基于Consumer 的治理策略。配置User 的流量流出规则， User 路由到Cart 时使⽤User 的流量流出规则。

#### 全链路灰度

​	继续考虑上⾯微服务体系中对服务Cart 进⾏发布的场景，如果此时服务Order 也需要发布新版本，由于本次新功能涉及到服务Cart 和Order 的共同变动，所以要求在灰度验证时能够使得灰度流量同时经过服务Cart 和Order 的灰度版本。如下图：

![](https://pic.imgdb.cn/item/62ab02ee09475431291b4ed2.jpg)

​	对于以上的问题，开发者结合实际业务场景和⽣产实践经验，提出了⼀种端到端的灰度发布⽅案，即全链路灰度。全链路灰度治理策略主要专注于整个调⽤链，它不关⼼链路上经过具体哪些微服务，流量控制视⻆从服务转移⾄请求链路上，仅需要少量的治理规则即可构建出从⽹关到整个后端服务的多个流量隔离环境，有效保证了多个亲密关系的服务顺利安全发布以及服务多版本并⾏开发，进⼀步促进业务的快速发展。

### 全链路灰度的解决⽅案

​	如何在实际业务场景中去快速落地全链路灰度呢？⽬前，主要有两种解决思路，基于物理环境隔离和基于逻辑环境隔离。

#### 物理环境隔离

![](https://pic.imgdb.cn/item/62ab033109475431291bf22e.jpg)